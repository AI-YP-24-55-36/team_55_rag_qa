## Файл посвящен изучению данных и построению различных визуализаций.

Наша **цель** - провести **разведочный анализ данных**, получить представление об их объеме, темах, выявить пропуски, дубликаты, найти особенности, **понять насколько связны тексты между колонками**, можно ли использовать этот датасет (как базу данных) для извлечения ответов в RAG.

Датасет взят из базы **huggingface**.
Название датасета  [neural-bridge/rag-dataset-12000](https://huggingface.co/datasets/neural-bridge/rag-dataset-12000)
Датасет состоит из 3-х колонок (контекст, вопрос, ответ):


<img width="347" alt="image" src="https://github.com/user-attachments/assets/7aba6bb6-7d5b-419c-bebd-f5dd6cd4df46">

Описание колонок:
**context** - это тексты из  [Falcon RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)—  набор веб-данных на английском языке, созданный TII и выпущенный по лицензии ODC-By 1.0.
**question** и **answer** - это вопросы и ответы, сгенерированные GPT-4.
В оригинале данные разделены на обучающую и тестовую выборку. Размеры разделения следующие: RAG Dataset 12000 | 9600 | 2400 |

Загрузка осуществляется с помощью библиотеки ``datasets`` и метода ``load_datasets``
``load_dataset("neural-bridge/rag-dataset-12000")``

В датасете отсутствуют полные дубликаты. Нет дубликатов в колонке answer. Есть дубли в колонке question. 


<img width="1047" alt="image 2" src="https://github.com/user-attachments/assets/12eebe5e-7f23-4717-b6b3-9a97bc1181b3">



В основном это некие общие вопросы вида “О чем этот контекст?”. Удаление таких  дублей не требуется, так как вопрос универсален и подойдет к любому контексту.

Обнаружено три строки с пропусками:


<img width="596" alt="image 3" src="https://github.com/user-attachments/assets/8709725f-41ab-4b9c-8c2d-5d628a842de3">



так как это 0,025% от всех данных, то эти строки можно порсто удалить.

## Длины текстов
Чтобы ценить объемы текстов в колонках были подсчитаны длины текстов в словах и в символах:


<img width="743" alt="image 4" src="https://github.com/user-attachments/assets/e11482d6-57d9-4032-a5c2-1fd978b98156">


В результате получаем выводы:
* Самая объемная по количеству текста - слов и символов колонка **context**, максимальный текст в этой колонке состоит из 1285 слов, минимальный из 19.
* в колонке question тексты от 3 до 56 слов
* Привлекли внимание записи в колонке **answer** длиной в 2 символа и в 1 слово, но после проверки, можно признать, что значение валидное (это ответ в виде двузначной цифры и коротким отрицательным словом)
* Минимальная длина текста 2 символа в колонке answer
* других аномалий нет

<img width="1288" alt="image" src="https://github.com/user-attachments/assets/569c6a70-c3fb-4955-9112-ceff3a246ba1">

<img width="1278" alt="image" src="https://github.com/user-attachments/assets/b9da7918-aac7-43d8-bd24-e098fa2e3aaa">


Средняя длина слов по колонкам варьируется от 2-х до 8-ми символов, что является нормой.
* Длина слова в 'context' чаще всего равна 5 символам, и редко используются слова меньше, чем из 3-х символов.
* 'question' - есть довольно много слов длиной до 4 символов
* 'answer' - есть довольно много слов длиной до 4 символов, есть слова от 2-х символов 



<img width="1256" alt="image 5" src="https://github.com/user-attachments/assets/1279cf0e-d5de-4077-b081-277cfe55f0d3">




Проведено исследование длин предложений с использованием ``nltk.sent_tokenize``

* основном количество предложений в поле 'context' достигает 100, небольшое количество предложений от 100 до 150. Значения довольно условное, так как sent_tokenize токенизирует “неидеально”.
* Вопросы 'question' в большинстве состоят из одного предложения
* Ответы 'answer'  состоят из 1 предложения, есть поля до 10 предложений, но их мало.

<img width="1245" alt="image 6" src="https://github.com/user-attachments/assets/6671be2c-fb45-492c-9c1c-616f7de396a5">


## Частотность

### частотность по словам

Чтобы посмотреть частотность, зафиксируем список стоп-слов 
``STOPWORDS = set(nltk.corpus.stopwords.words('english') + ['-', '-', '–','&'])``
Далее смотрим распределение по частотности:
**context**:
наиболее частотные стоп-слова - это артикли, предлоги, тире наиболее частот НЕ стоп-слова - числительное one, наречие also, прилагательное new, довольно обычный набор слов, свойственный повестованию

<img width="1269" alt="image 7" src="https://github.com/user-attachments/assets/f59d2a22-d699-4199-b2e5-35e4de0e7e06">


**question**:
наиболее частотные стоп-слова - это артикль the, вопросительное слово what, who, предлоги наиболее частот НЕ стоп-слова - context, according, purpose, то есть некие уточняющие слова, которые могут использоваться в вопросах, в первом приближении, можно подтвердить адекватность содержимого

<img width="1319" alt="image 8" src="https://github.com/user-attachments/assets/b7a22aed-1a2e-4884-b47f-958269c3de92">

**answer**:
наиболее частотные стоп-слова - это артикль the, предлоги наиболее частот НЕ стоп-слова - топ слов пересекается с колонкой context, например, one, new, main, like, можно предположить, что ответы связаны с контекстом, основаны на контексте

<img width="1281" alt="image 9" src="https://github.com/user-attachments/assets/1d22006a-e468-4544-8db3-ed89263c3664">

### частотность по n-граммам
для извлечения играм используется 
``CountVectorizer(ngram_range=(n, n), lowercase=True)``

#### биграммы

<img width="1393" alt="image 10" src="https://github.com/user-attachments/assets/58a0c566-4d8e-4151-bb15-c11d2b62b11a">

* Для контекста сочетания из дву слов в большинстве случаев это службные связки, свойственные для английского языка, а также указание на возраст (year old)
* Для вопросов словосочетания - первое место covid 19 (его актуальность не удивляет), указание на время, долгосрочность, победителей в играх, конкурсах
* ответы коррелируют с вопросами по набору словосочетаний: также временные значения, возраст, ковид, появилось сочетание высокое качество, которое не вошло в топ ни в вопросах, ни в ответах, возможно связано с запросом о победах
#### триграммы

<img width="1418" alt="image 11" src="https://github.com/user-attachments/assets/0e46a006-6363-42af-b25b-e649499b6ea9">

* Для контекста на первом месте сочетание, связанное с соцсетью твиттер, значит в повествовании есть отсылки к материалам в твиттер. Далее идет состояние, искусство, такие вспомогательные сочетания, как "день ото дня", "один на один", "шаг за шагом", своственные повествованию, всплывает тема школы
* Для вопросов опять таки в топе возраст, далее упоминуются "будущие мамы", компьютерное техническое образование, уровень выше среднего
* В ответах есть упоминание искусства, состояния, возраста, ответы больше перекликаются с контекстом

### Облака слов WORDCLOUD
Для того, чтобы получить диаграммы выполним препроцессинг текста, в работе используется две разные функции для “очищения” текста - разной степени обработки.
Для построения WORDCLOUD удаляем, стоп-слова, все символы, кроме букв, лемматизируем, приводим к нижнему регистру. Строим график для 100 слов:
    ``wordcloud = WordCloud(
        background_color='white',
        stopwords = STOPWORDS,
        max_words=100,
        max_font_size=30,
        scale=3,
        random_state=1)``
**context**

<img width="954" alt="image 12" src="https://github.com/user-attachments/assets/a15cab8d-6e7f-4299-ac52-ed3e601f4d71">

Привлекает внимание - мода, европейский, италия, ассистент, вещь, ад, ассоциация, фирма, пенсильвания, бариста, выходные
**question**

<img width="983" alt="image 13" src="https://github.com/user-attachments/assets/f14a84c0-785b-49af-ac8d-db280b4988f8">


Привлекает внимание - территория, исслевование, продажа, дом, работа, свойства, кофе, даты выходные
**answer**

<img width="952" alt="image 14" src="https://github.com/user-attachments/assets/e19e7468-29d8-487d-b8e1-e482f592bdbd">

Частотное слово include, возможно свойственно для построения ответа, упоминаются конкретные имена собственные, кофе, фото, продажи.
Диаграммы подтверждают гипотезу о связности текстов в колонках.

### TSNE

t-SNE — метод уменьшения размерности, в данном случае, мы используем его для визуализации расстояний между словами, плотности различных секций слов и отображения расстояний между группами слов.
Визуализация построена на колонки  **context** для улучшения представления её о содержимом.
Для построения диаграммы необходимо векторизовать слова. Для этого используется  Word2Vec из библиотеки [gensim](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html) . Для начала готовим корпус слов, на котором модель будет обучена, составлен словарь, с помощью которого слова будут преобразовываться в вектора.
С помощью  ``FreqDist`` из ``nltk`` составляем словарь из 200 наиболее частотных слов, на основе которых будет построена визуализация.
Визуализация выполнена с помощью библиотеки ``bokeh.models`` [Bokeh documentation](https://docs.bokeh.org/en/latest/)


<img width="970" alt="image 15" src="https://github.com/user-attachments/assets/e97a404e-87d6-452b-b049-b16b21b8894b">


Альтернативный график с помощью plotly.express


<img width="1356" alt="image 16" src="https://github.com/user-attachments/assets/195d4df6-390c-4620-a561-ea712fc7c7eb">

второй график дает дополнительную информацию в виде легенды частотности иболее интерактивен, позволяет включать/выключать слова

Трехмерный график показал оторванность слова **today** можно списать на недостаток работы в модели векторизации

<img width="1051" alt="image 17" src="https://github.com/user-attachments/assets/4ad74385-b18a-4303-8f87-f05aff594e2d">

По диаграммам **TSNE** не выявлено отдельных обособленных скоплений, в основном слова находятся на небольшом расстоянии, хорошо выявлены близкие по смыслу и синонимы. Видно что есть скопления, связанные с временными характеристиками, такими как год, минута, час, день и т.д. что-то с образованием - школа, студенты, университет. С конкретными персонами, с продажами и ценами, местоположением - мир, америка, с публикациями - комментарии, отчеты, медиа и т.д.

### Topic modeling

Для выделения тематических топиков используется [gensim.models.LdaMulticore](https://tedboy.github.io/nlps/generated/generated/gensim.models.LdaMulticore.html)  для составления словаря [gensim.corpora.Dictionary](https://tedboy.github.io/nlps/generated/generated/gensim.corpora.Dictionary.html), в качестве гиперпараметра указывается количество тем, на которые мы хотим разбить тексты.  Для визуализации используется библиотека pyLDAvis - извлекает информацию из подобранной тематической модели LDA для интерактивной веб-визуализации.
Сделаем несколько визуализаций.
Предварительно подготовим столбец с нграммами со следующими гиперпараметрами:
``CountVectorizer(ngram_range=(2, 3),token_pattern=r'[A-Za-z]+', stop_words = STOPWORDS, min_df=10)``
Обучим модель на столбце с н-граммами, получаем следующий результат:

<img width="1392" alt="image 18" src="https://github.com/user-attachments/assets/f4aa746c-abab-48f4-803f-4eeca5610171">

метод отображает топики и слова, которые к отнесены к теме.
Нагляднее можно посмотреть на графике:


<img width="1314" alt="image 19" src="https://github.com/user-attachments/assets/ea6533ed-0005-4799-8bb7-89035d86e0aa">


Площадь каждого круга представляет важность темы относительно корпуса Расстояние между центрами кругов указывает на сходство между темами Гистограмма справа показывает 30 самых релевантных теме слов, по-другому их можно назвать ключевые слова. С помощью регулирования параметра лямбда можно изменять метрику релевантности. Темы не пересекаются и находятся на расстоянии между собой, что говорит о том, что можно выделить и большее количество тем, чем 10.
Тема 1 - наиболее релевантными словами являются: one, like, love, people, book (условно говоря тема о предпочтениях людей).
Тема 2 - сервис, бизнес, работа, продукт, софт
Тема 3 - здоровье, закон, правильство, сервис, забота
Тема 4 - игры, команды, сезон, игроки
Тема 5 - машины, дизайн, модели
Тема 6 - отели, номера, свадьбы, казино
Тема 7 - школа, университет, семья, церковь
Тема 8 - еда, зелень, курица, яйца, блюда, рецепты
Тема 9 - музей, искусство, комьюнити, история, премия
Тема 10 - фильмы, музыка, forex, инвесторы, трейдинг, магазины
Самые многочисленные топики - 1, 2, 3 темы
_________
Построим анализ контекста по столбцу с **context** очищенному от "шума"


<img width="1385" alt="image 20" src="https://github.com/user-attachments/assets/8fd52446-5642-4c7d-9a55-f288a1151197">


По большей части темы получились похожие, что позволяет уже сделать выводы о чем наш основной столбец с контекстами, это:
1. тексты о спорте,
2. компьютерных играх,
3. отдыхе в отелях (пляж/виды) + семейных мероприятиях/праздниках,
4. об образовании,
5. об искусстве (музеях, кинематографе),
6. о здоровье и зравоохранении
7. рецепты/еда
8. компьютерная индустрия
9. компании, бизнес
10. торговля, магазины, покупки, электронная торговля
______
Построим анализ контекста по столбцу с **question**

<img width="1239" alt="image 21" src="https://github.com/user-attachments/assets/13c00d93-8ee2-4eed-9a57-23a2ca9d1520">


По темам вопросов видим, что ключевыми словами самой многочисленной темы является:
авторы/книги/школы/ингридиенты/компании/цели/год(как дата/веб-сайты/города
персонажи/игры/выгода/предложение/награда
игроки/спорт/счет
упоминаются соцсети/города
есть храктерные для вопросов слова, такие как согласно/цели/роли/названия
В целом можно сделать вывод, что вопросы довольно связаны с темами контекста
_____
Построим анализ контекста по столбцу с **answer**


<img width="1320" alt="image 22" src="https://github.com/user-attachments/assets/e9ea0d96-8ab8-48ad-b936-72e4b6b977f2">



По ответам выделены темы, содержащие ключевые слова
сервисы/информация/пользователи/данные/студенты/бизнес/работа/цели/саппорт/дизайн/видео
дома/цена/уровень/риски/качество/количество/рейтинг/магазины
еда/перец/сахар/курица и т.д. связанное с рецептами
женщины/вечеринки/рестораны/кухня/гости
города/национальности/население и т.д.
**Вывод по тематическому моделированию:**
При более внимательном рассмотрении не было обнаружено тем, которые не освещены в контексте. Можно утвердиться в предположении о связности текстов. В вопросах часто фигурирует слово context, то есть в вопросе часто есть указание где искать ответ.

### Parts of speech tagging

Анализ на части речи дополнит представление о содержании текстов, о стилистике, покажет распределение топ частей речи. Для выявления частей речи используем nltk модель averaged_perceptron_tagger (модель обучена на основе персептрона). Анализ проводим по очищенному нормализованному тексту без пунктуации и посторонних символов. Основные части речи, которые выделяет модель
* Noun (NN) - Существительное
* NNS - существительное в множественном числе
* Verb (VB) - Глагол
* Adjective (JJ) - Прилагательное
* Adverb (RB) - Наречие
* Preposition (IN)- Предлог
* Conjunction (CC) - Союз
* Pronoun (PRP) - Местоимение
* Interjection (INT) - Междометие
* NNP означает существительное собственное
* DT - артикли
* CD - дата

колонка **context**

<img width="1304" alt="image 23" src="https://github.com/user-attachments/assets/2e9d258a-24f0-458a-af6a-b55400994b46">


Ожидаемо в тексте большинство существительных, в контексте - это слова, связанные с датой, работой, играми, вещами, жизнью.  Не нарушена стилистичекая конструкция построения предложений при повестовании.

Анализ колонки **question**

<img width="1265" alt="image 24" src="https://github.com/user-attachments/assets/a62ac16b-69f5-43ba-8a32-0dfd291bfe4a">


В вопросах, часто упоминается само слово context, то есть вопрос часто отсылает к конкретному столбцу, где искать ответ. Также вопросы связаны с такими словами как автор, цели, события, книги, игры, роли.

Анализ колонки **answer**

<img width="1260" alt="image 25" src="https://github.com/user-attachments/assets/1358bdd9-8e9f-44a8-b284-facb1fe89fc0">

Большинство ответов базируется на существительных автор, время, опять же контекст, система, бизнес, сервис, вода.
Вопросы и ответы связаны по насыщенности существительных, на которых базируется предложение.

###  Named entity recognition

Для извлечени именованных сущностей используется библиотека spacy, модель en_core_web_sm (English pipeline optimized for CPU. Components: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer / written text (blogs, news, comments)) - модель обучена на английском языке на письменном веб-тексте (блоги, новости, комментарии), включает в себя слова, синтаксис и сущности ~[Модели](https://www.google.com/url?q=https%3A%2F%2Fspacy.io%2Fmodels%2Fen)~
Сущности, которые выделяет модель:
PERSON - People, including fictional.
NORP - Nationalities or religious or political groups.
FAC - Buildings, airports, highways, bridges, etc.
ORG - Companies, agencies, institutions, etc.
GPE - Countries, cities, states.
LOC - Non-GPE locations, mountain ranges, bodies of water.
PRODUCT - Objects, vehicles, foods, etc. (Not services.)
EVENT - Named hurricanes, battles, wars, sports events, etc.
WORK_OF_ART - Titles of books, songs, etc.
LAW - Named documents made into laws.
LANGUAGE - Any named language.
DATE - Absolute or relative dates or periods. TIME - Times smaller than a day.
PERCENT - Percentage, including "⅒".
MONEY - Monetary values, including unit.
QUANTITY - Measurements, as of weight or distance.
ORDINAL - "first", "second", etc.
CARDINAL - Numerals that do not fall under another type.

Колонка **context** 

<img width="1300" alt="image 26" src="https://github.com/user-attachments/assets/a99a97b1-bc73-4fb0-be9c-e92f4caa4934">


Эти графики также дают нам представление о сути имеющихся текстов, видно, что в текстах речь о персонах/людях, о датах, числительных, организациях, локациях, национальностях, политических группах,  времени, о водоемах, ландшафте. 
При рассмотрении топовой категории - персоны: видим, что речь идет о конкретных именах.

Графики по колонкам с вопросами и ответами показывают похожее распределение.

Колонка **question**

<img width="1337" alt="image 27" src="https://github.com/user-attachments/assets/91c6c750-3803-46ea-9eaf-b060d7c0ca14">


Колонка **answer**


<img width="1337" alt="image 28" src="https://github.com/user-attachments/assets/9618b1a7-57b8-489a-890e-74a8be9006ff">




### Выводы:

Данные в датасете консистентны, прослеживается связь ``вопрос - контекст - ответ``.
Cодержание текстов о жизни, о насущных проблематиках:
- отдых/путешествия/времяпрепровождение
- образование
- книги/фильмы
- рецепты
- события в мире искусства
- премии награждения
- компьютерная индустрия и компьютерные игры
Также видно, что вопросы какаются конкретных личностей, определенных мест или локаций, актуальных болезней. 
**Данные подойдут для вопросно - ответной системы.**























