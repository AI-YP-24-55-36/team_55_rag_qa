## Файл посвящен изучению данных и построению различных визуализаций.

Наша **цель** - провести **разведочный анализ данных**, получить представление об их объеме, темах, выявить пропуски, дубликаты, найти особенности, **понять насколько связны тексты между колонками**, можно ли использовать этот датасет (как базу данных) для извлечения ответов в RAG.

Датасет взят из базы **huggingface**.
Название датасета  [neural-bridge/rag-dataset-12000](https://huggingface.co/datasets/neural-bridge/rag-dataset-12000)
Датасет состоит из 3-х колонок (контекст, вопрос, ответ):


<img width="347" alt="image" src="https://github.com/user-attachments/assets/7aba6bb6-7d5b-419c-bebd-f5dd6cd4df46">

Описание колонок:
**context** - это тексты из  [Falcon RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)—  набор веб-данных на английском языке, созданный TII и выпущенный по лицензии ODC-By 1.0.
**question** и **answer** - это вопросы и ответы, сгенерированные GPT-4.
В оригинале данные разделены на обучающую и тестовую выборку. Размеры разделения следующие: RAG Dataset 12000 | 9600 | 2400 |

Загрузка осуществляется с помощью библиотеки ``datasets`` и метода ``load_datasets``
``load_dataset("neural-bridge/rag-dataset-12000")``

В датасете отсутствуют полные дубликаты. Нет дубликатов в колонке answer. Есть дубли в колонке question. 


<img width="1062" alt="image" src="https://github.com/user-attachments/assets/03f23b9d-6066-41d9-b022-18a6d1c77f4a">

Видим, что есть повторяющиеся вопросы, но это скорее вопросы общего характера, могут быть использованы к разным контекстам, возможно нужно будет в будущем избавиться от таких строк, так как вопросы одинаковые, при этом контексты отличаются по наполнению, ответы разные. То, что вопросы одинаковые - ответы разные, может повлиять на работу модели в будущем.  

Также обнаружены несколько строк с NaN.  

Обнаружено три строки с пропусками:  

<img width="533" alt="image" src="https://github.com/user-attachments/assets/ebcba38a-fba8-4d6e-b173-4fb46eeb67f0">

так как это 0,025% от всех данных, то эти строки можно порсто удалить.

В колонке context в тексте содержится знак перевода строки (\n), как разделитель между словами, в некоторых случаях предложениями, почистим текст от этих символов.

<img width="626" alt="image" src="https://github.com/user-attachments/assets/c07853d4-115a-4289-82f2-fb5d75715dca">


## Длины текстов
Чтобы ценить объемы текстов в колонках были подсчитаны длины текстов в словах и в символах:


<img width="743" alt="image 4" src="https://github.com/user-attachments/assets/e11482d6-57d9-4032-a5c2-1fd978b98156">


В результате получаем выводы:
* Самая объемная по количеству текста - слов и символов колонка **context**, максимальный текст в этой колонке состоит из 1285 слов, минимальный из 19.
* в колонке question тексты от 3 до 56 слов
* Привлекли внимание записи в колонке **answer** длиной в 2 символа и в 1 слово, но после проверки, можно признать, что значение валидное (это ответ в виде двузначной цифры и коротким отрицательным словом)
* Минимальная длина текста 2 символа в колонке answer
* других аномалий нет

<img width="1288" alt="image" src="https://github.com/user-attachments/assets/569c6a70-c3fb-4955-9112-ceff3a246ba1">

<img width="1278" alt="image" src="https://github.com/user-attachments/assets/b9da7918-aac7-43d8-bd24-e098fa2e3aaa">


Средняя длина слов по колонкам варьируется от 2-х до 8-ми символов, что является нормой.
* Длина слова в 'context' чаще всего равна 5 символам, и редко используются слова меньше, чем из 3-х символов.
* 'question' - есть довольно много слов длиной до 4 символов
* 'answer' - есть довольно много слов длиной до 4 символов, есть слова от 2-х символов 



<img width="1256" alt="image 5" src="https://github.com/user-attachments/assets/1279cf0e-d5de-4077-b081-277cfe55f0d3">




Проведено исследование длин предложений с использованием ``nltk.sent_tokenize``

* основном количество предложений в поле 'context' достигает 100, небольшое количество предложений от 100 до 150. Значения довольно условное, так как sent_tokenize токенизирует “неидеально”.
* Вопросы 'question' в большинстве состоят из одного предложения
* Ответы 'answer'  состоят из 1 предложения, есть поля до 10 предложений, но их мало.

<img width="1245" alt="image 6" src="https://github.com/user-attachments/assets/6671be2c-fb45-492c-9c1c-616f7de396a5">


## Частотность

### частотность по словам

Чтобы посмотреть частотность, зафиксируем список стоп-слов 
``STOPWORDS = set(nltk.corpus.stopwords.words('english') + ['-', '-', '–','&'])``
Далее смотрим распределение по частотности:
**context**:
наиболее частотные стоп-слова - это артикли, предлоги, тире наиболее частот НЕ стоп-слова - числительное one, наречие also, прилагательное new, довольно обычный набор слов, свойственный повестованию

<img width="1239" alt="image" src="https://github.com/user-attachments/assets/c8bdbd35-6d41-4634-ab48-ea63a456b136">


**question**:
наиболее частотные стоп-слова - это артикль the, вопросительное слово what, who, предлоги наиболее частот НЕ стоп-слова - context, according, purpose, то есть некие уточняющие слова, которые могут использоваться в вопросах, в первом приближении, можно подтвердить адекватность содержимого

<img width="1226" alt="image" src="https://github.com/user-attachments/assets/9aabeafb-9226-47a2-96ff-70d7ff342a08">


**answer**:
наиболее частотные стоп-слова - это артикль the, предлоги наиболее частот НЕ стоп-слова - топ слов пересекается с колонкой context, например, one, new, main, like, можно предположить, что ответы связаны с контекстом, основаны на контексте

<img width="1230" alt="image" src="https://github.com/user-attachments/assets/bddc2569-d9f3-4250-afb9-3a20474c650b">


### частотность по n-граммам
для извлечения играм используется 
``CountVectorizer(ngram_range=(n, n), lowercase=True)``

#### биграммы

<img width="1622" alt="image" src="https://github.com/user-attachments/assets/aac57bdd-73e9-4652-9d76-e40a7ca8a7d1">


* Для контекста сочетания из двух слов в большинстве случаев это служебные связки, свойственные для английского языка.
* Для вопросов словосочетания - первое место вопросительное слово, также часто упоминается the context (нужно обратить внимание).
* В ответах довольно много предлогов, указывающих на место, частое упоминание the author.
#### триграммы

<img width="1652" alt="image" src="https://github.com/user-attachments/assets/8448c5e2-d441-4c53-b49a-9c79222a9f31">


* Для контекста связки, храрктерные для описания чего-либо.
* Для колонки с вопросами - связки, указывающие на вопросительные предложения.
* В ответах связки, использующиеся для объяснения чего-либо.

### Облака слов WORDCLOUD
Для того, чтобы получить диаграммы выполним препроцессинг текста, в работе используется две разные функции для “очищения” текста - разной степени обработки.
Для построения WORDCLOUD удаляем, стоп-слова, все символы, кроме букв, лемматизируем, приводим к нижнему регистру. Строим график для 100 слов:
    ``wordcloud = WordCloud(
        background_color='white',
        stopwords = STOPWORDS,
        max_words=100,
        max_font_size=30,
        scale=3,
        random_state=1)``
**context**

<img width="942" alt="image" src="https://github.com/user-attachments/assets/e5e1d013-3429-4a6d-a447-16aa5f8fea85">

Выделяются слова: работа, бизнес, продукт, люди, компания, время, год, игра, команда, сервис, книга, помощь. Часто встреющиеся глаголы: нравится, думать, использовать, знать, искать.

**question**

<img width="940" alt="image" src="https://github.com/user-attachments/assets/696271fa-92a8-4655-86e5-93a8e063358a">

Привлекает внимание - цель, процесс, проблема, автор, упоминание, главный. Слово context, как было замечено ранее, много вопросов сформулировано с помощью этого слова, как указателя, где искать ответ.

**answer**

<img width="937" alt="image" src="https://github.com/user-attachments/assets/3c550f34-5024-4a81-9890-55549c0e98b0">

Частотные слова: продукт, бизнес, сервис, компания, игра, включать, помощь, команда, нравится, студент, книга. Видно, что по частотности слова пересекаются с контекстом.

Диаграммы подтверждают гипотезу о связности текстов в колонках, так как темы, с которыми связаны ключевые слова, в разных колонках повторяются.


### TSNE

t-SNE — метод уменьшения размерности, в данном случае, мы используем его для визуализации расстояний между словами, плотности различных секций слов и отображения расстояний между группами слов.
Визуализация построена на колонки  **context** для улучшения представления её о содержимом.
Для построения диаграммы необходимо векторизовать слова. Для этого используется  Word2Vec из библиотеки [gensim](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html) . Для начала готовим корпус слов, на котором модель будет обучена, составлен словарь, с помощью которого слова будут преобразовываться в вектора.
С помощью  ``FreqDist`` из ``nltk`` составляем словарь из 200 наиболее частотных слов, на основе которых будет построена визуализация.
Визуализация выполнена с помощью библиотеки ``bokeh.models`` [Bokeh documentation](https://docs.bokeh.org/en/latest/)


<img width="1309" alt="image" src="https://github.com/user-attachments/assets/e1533375-5494-49b2-bf0f-ef86bf481742">


Альтернативный график с помощью plotly.express


<img width="1570" alt="image" src="https://github.com/user-attachments/assets/049e9487-9bed-4eba-9aca-f23e4564703b">



второй график дает дополнительную информацию в виде легенды частотности иболее интерактивен, позволяет включать/выключать слова

Трехмерный график показал оторванность слова **today** (howewer, и глаголf think) можно списать на недостаток работы модели по определению близости по векторам

<img width="1748" alt="image" src="https://github.com/user-attachments/assets/3e6165d4-eb77-416b-985d-128cf6b26144">

По диаграммам **TSNE** не выявлено отдельных обособленных скоплений, в основном слова находятся на небольшом расстоянии, хорошо выявлены близкие по смыслу и синонимы. Видно что есть скопления, связанные с временными характеристиками, такими как год, минута, час, день и т.д. что-то с образованием - школа, студенты, университет. С конкретными персонами, с продажами и ценами, местоположением - мир, америка, с публикациями - комментарии, отчеты, медиа и т.д.

### Topic modeling

Для выделения тематических топиков используется [gensim.models.LdaMulticore](https://tedboy.github.io/nlps/generated/generated/gensim.models.LdaMulticore.html)  для составления словаря [gensim.corpora.Dictionary](https://tedboy.github.io/nlps/generated/generated/gensim.corpora.Dictionary.html), в качестве гиперпараметра указывается количество тем, на которые мы хотим разбить тексты.  Для визуализации используется библиотека pyLDAvis - извлекает информацию из подобранной тематической модели LDA для интерактивной веб-визуализации.
Сделаем несколько визуализаций.
Предварительно подготовим столбец с нграммами со следующими гиперпараметрами:
``CountVectorizer(ngram_range=(2, 3),token_pattern=r'[A-Za-z]+', stop_words = STOPWORDS, min_df=10)``
Обучим модель на столбце с н-граммами, получаем следующий результат:

<img width="1528" alt="image" src="https://github.com/user-attachments/assets/885c3310-7919-4b83-8f46-8b20155383d1">

метод отображает топики и слова, которые к отнесены к теме.
Нагляднее можно посмотреть на графике:

<img width="1234" alt="image" src="https://github.com/user-attachments/assets/0d197a81-8799-4f05-aa36-1958f37422cf">

Площадь каждого круга представляет важность темы относительно корпуса  
Расстояние между центрами кругов указывает на сходство между темами
Гистограмма справа показывает 30 самых релевантных теме слов, по-другому их можно назвать ключевые слова. С помощью регулирования параметра лямбда можно изменять метрику релевантности. Темы не пересекаются и находятся на расстоянии между собой, что говорит о том, что можно выделить и большее количество тем, чем 10. Темы:

-  наиболее релевантными словами являются: one, like, love, people, book (условно говоря тема о предпочтениях людей).

- сервис, бизнес, работа, продукт, софт

- здоровье, медицина, закон, правильство, сервис, забота

- игры, команды, сезон, игроки

- машины, дизайн, модели

- отели, номера, свадьбы, казино

- школа, университет, семья, церковь

- еда, зелень, курица, яйца, блюда, рецепты

- музей, искусство, комьюнити, история, премия

- фильмы, музыка, forex, инвесторы, трейдинг, магазины

Самые многочисленные топики - 1, 2, 3 темы
_________
Построим анализ контекста по столбцу с **context** очищенному от "шума"

<img width="1215" alt="image" src="https://github.com/user-attachments/assets/2fda182a-f3da-4b6e-b3cc-b4854954c26f">

По большей части темы получились похожие, что позволяет уже сделать выводы о чем наш основной столбец с контекстами, это:

- тексты о спорте,
- компьютерных играх,
- отдыхе в отелях (пляж/виды) + семейных мероприятиях/праздниках,
- об образовании,
- об искусстве (музеях, кинематографе),
- о здоровье и зравоохранении
- рецепты/еда, диета
- компьютерная индустрия
- компании, бизнес
- торговля, магазины, покупки, электронная торговля

______
Построим анализ контекста по столбцу с **question**

<img width="1212" alt="image" src="https://github.com/user-attachments/assets/8c211e2e-db8a-4d99-8ce5-15bae475050b">

По темам вопросов видим, что ключевыми словами самой многочисленной темы является:
авторы/книги/школы/ингридиенты/компании/цели/год(как дата/веб-сайты/города
персонажи/игры/выгода/предложение/награда
игроки/спорт/счет
упоминаются соцсети/города
есть храктерные для вопросов слова, такие как согласно/цели/роли/названия
В целом можно сделать вывод, что вопросы довольно связаны с темами контекста
_____
Построим анализ контекста по столбцу с **answer**

<img width="1198" alt="image" src="https://github.com/user-attachments/assets/dc996d23-0065-43b4-828f-0b59781b3ea5">


По ответам выделены темы, содержащие ключевые слова  
сервисы/информация/пользователи/данные/студенты/семья/бизнес/работа/цели/саппорт/дизайн/видео  
дома/цена/уровень/риски/качество/количество/рейтинг/магазины  
еда/перец/сахар/курица и т.д. связанное с рецептами  
женщины/вечеринки/рестораны/кухня/гости  
города/национальности/население и т.д.  
**Вывод по тематическому моделированию:**    
При более внимательном рассмотрении не было обнаружено тем, которые не освещены в контексте. Можно утвердиться в предположении о связности текстов. В вопросах часто фигурирует слово context, то есть в вопросе часто есть указание где искать ответ.  

### Parts of speech tagging

Анализ на части речи дополнит представление о содержании текстов, о стилистике, покажет распределение топ частей речи. Для выявления частей речи используем nltk модель averaged_perceptron_tagger (модель обучена на основе персептрона). Анализ проводим по очищенному нормализованному тексту без пунктуации и посторонних символов. Основные части речи, которые выделяет модель
* Noun (NN) - Существительное
* NNS - существительное в множественном числе
* Verb (VB) - Глагол
* Adjective (JJ) - Прилагательное
* Adverb (RB) - Наречие
* Preposition (IN)- Предлог
* Conjunction (CC) - Союз
* Pronoun (PRP) - Местоимение
* Interjection (INT) - Междометие
* NNP означает существительное собственное
* DT - артикли
* CD - дата

колонка **context**

<img width="1256" alt="image" src="https://github.com/user-attachments/assets/01bf52eb-53eb-455e-88c8-9638222de513">


Ожидаемо в тексте большинство существительных, в контексте - это слова, связанные с датой, работой, играми, вещами, жизнью.  Не нарушена стилистичекая конструкция построения предложений при повестовании.

Анализ колонки **question**

<img width="1257" alt="image" src="https://github.com/user-attachments/assets/4d74f7e5-955b-47b0-9ee2-0a5bc566eff6">


В вопросах, часто упоминается само слово context, то есть вопрос часто отсылает к конкретному столбцу, где искать ответ. Также вопросы связаны с такими словами как автор, цели, события, книги, игры, роли.

Анализ колонки **answer**


<img width="1253" alt="image" src="https://github.com/user-attachments/assets/cf006081-a140-4da6-b236-80a7fb301fd0">

Большинство ответов базируется на существительных автор, время, опять же контекст, система, бизнес, сервис, вода. Так как график строится на колонке без очистки текста то в топ попал знак % (в ответах этот символов может иметь смысловое значение, так как в текстах есть информация по цифрам).

###  Named entity recognition

Для извлечени именованных сущностей используется библиотека spacy, модель en_core_web_sm (English pipeline optimized for CPU. Components: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer / written text (blogs, news, comments)) - модель обучена на английском языке на письменном веб-тексте (блоги, новости, комментарии), включает в себя слова, синтаксис и сущности [Модели](https://www.google.com/url?q=https%3A%2F%2Fspacy.io%2Fmodels%2Fen)

Сущности, которые выделяет модель:

PERSON - People, including fictional.  
NORP - Nationalities or religious or political groups.  
FAC - Buildings, airports, highways, bridges, etc.  
ORG - Companies, agencies, institutions, etc.  
GPE - Countries, cities, states.  
LOC - Non-GPE locations, mountain ranges, bodies of water.  
PRODUCT - Objects, vehicles, foods, etc. (Not services.)  
EVENT - Named hurricanes, battles, wars, sports events, etc.  
WORK_OF_ART - Titles of books, songs, etc.  
LAW - Named documents made into laws.  
LANGUAGE - Any named language.  
DATE - Absolute or relative dates or periods. TIME - Times smaller than a day.  
PERCENT - Percentage, including "⅒".   
MONEY - Monetary values, including unit.  
QUANTITY - Measurements, as of weight or distance.  
ORDINAL - "first", "second", etc.  
CARDINAL - Numerals that do not fall under another type.  

Колонка **context** 

<img width="1299" alt="image" src="https://github.com/user-attachments/assets/36e73cb7-cfd8-4e53-9d08-7b1393396fda">

Эти графики также дают нам представление о сути имеющихся текстов, видно, что в текстах речь о персонах/людях, о датах, числительных, организациях, локациях, национальностях, политических группах,  времени, о водоемах, ландшафте. 
При рассмотрении топовой категории - персоны: видим, что речь идет о конкретных именах.

Графики по колонкам с вопросами и ответами показывают похожее распределение.

Колонка **question**

<img width="1292" alt="image" src="https://github.com/user-attachments/assets/b795f529-ce64-451f-9e14-e9cecadacdce">

Колонка **answer**

<img width="1289" alt="image" src="https://github.com/user-attachments/assets/f181c7ae-d709-42de-bd6a-206e432026c8">

**Выводы:**

Данные в датасете консистентны, прослеживается связь вопрос - контекст - ответ.

Содкржание текстов о жизни, о насущных проблематиках, которые часто обсуждаются в разных сферах:  
- отдых/путешествия/времяпрепровождение  
- образование  
- книги/фильмы  
- рецепты  
- события в мире искусства  
- премии награждения  
- компьютерная индустрия и компьютерные игры  


Также видно, что вопросы какаются конкретных личностей, определенных мест или локаций, актуальных болезней. Данные подойдут для вопросно - ответной системы.

Для применения датасета в модель, нужно определиться со стратегией препроцессинга, сформировав свой список стоп-слов, например, смущает частоттное слово "the context" в колонке с вопросами. Нужно принять решение, что делать с дубликатами в колонке с вопросами.






















