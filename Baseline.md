В файле `ipynb_base/baseline.ipynb` содержится базовая модель:
1. загрузка датасета
2. предобработка данных
3. инициализация энкодера (`Tf-idf`) для векторов 
4. создание коллекции данных (`create_collection`) для загрузки БД (`Qdrant`)
5. загрузка данных в БД (`upload_points`)
6. поиск данных `qdrant.search`
7. для каждого вопроса был извлечен ответ по косинусному сходству
8. рассчитана точность

В данном случае использовалась метрика **Precision**, так как мы установили, что у нас есть только один контекст для конкретного вопроса, и мы можем измерить точность того, что модель извлекла при поиске по косинусному сходству из БД и сопоставить с оригиналом. 

Было проведено множество экспериментов с различнвми моделями для выбора лучшей, результаты в таблице

| Модель | Точность |
|:------------:|:------------:|
| Word2Vec  | 28.5  |
| Fasttext  | 36.6  |
| glove-twitter-100  | 13  |
| all-MiniLM-L6-v2  | 75 |
| tf-idf  | 85.9  |

**Лучшая Базовая модель tf-idf показала точность 85.9%.**
