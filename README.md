# Построение вопросно-ответной системы с использованием RAG (retrieval-augmented generation)

В этом проекте мы построим RAG систему, задачей которой является ответы на вопросы пользователя по базе знаний, на которой модель, генерирующая ответ, не обучалась. Дополнительно будет создан интерфейс взаимодействия с пользователем.  
Работа RAG включает в себя этапы:
1. Принятие вопроса пользователя
2. Поиск тематически похожих документов, извлечение из векторной БД (Текущий реализлованный этап)
3. Передача документа генератору
4. Процесс генерации ответа с помошью LLM
5. Предоставление ответа



## Куратор - Георгий Панчук

* tg: [@jmzzomg](https://t.me/jmzzomg "Георгий")
* github: [@joein](github.com/joein "Георгий")

## Список участников

* Евгений Яковенко – tg: [@Yakovenko_evgenii](https://t.me/Yakovenko_evgenii "Евгений"), github: [@yakovenko96](https://github.com/yakovenko96 "Евгений")
* Людмила Теплова – tg: [@lteplova](https://t.me/lteplova "Людмила"), github: [@lteplova](https://github.com/lteplova "Людмила")
* Альберт Тайчинов – tg: [@tayar902](https://t.me/tayar902 "Альберт"), github: [@tayar902](https://github.com/tayar902 "Альберт")
* Алексей Ятковский – tg: [@BlackR_original](https://t.me/BlackR_original "Алексей"), github [@Aleksei-Ia](https://github.com/Aleksei-Ia "Алексей")


## Файлы с результатами работы:

1. Разведочный анализ данных
* EDA.md
* EDA_RAG_neural_bridge_rag_dataset_12000.ipynb
* requirements.txt
2. Baseline model
* Baseline.md
* ipynb_base/Baseline.ipynb
* ipynb_base/ файлы с экспериментами участников
3. MVP - app
* fastapi/ - backend
* streamlit/ - frontend
* grafana/ - config для отображения логов
* loki.yaml, promtail.yaml - config для сбора логов
* docker-compose 

## Приложение развернуто на VPS:

1. Арендовали сервер, с предустановленной ubuntu.
2. Через консоль подключились, создали нового пользователя, установили docker, docker compose и дали права для запуска без sudo.
3. На локальной машине создали ssh ключ и передали его на vps. Для быстрого захода через консоль без пароля и возможности передачи файлов.
4. С помощью консоли и sftp передаем файлы приложения.
5. Поднимаем docker compose на сервере.

* http://178.130.43.233:8501/
* http://178.130.43.233:3000/ - Мониторинг и визуализацияя приложения и логов
Сервер очень слабый и полный функционал приложения показать не сможет, максимум допустимый датасет для использования на сервере должен содержать не более 100 записей.


## Запуск приложения на локальной машине:

Для запуска требуется 
1. Установить по инструкции docker в зависимости от ОС https://docs.docker.com/compose/install/
2. В папке app прописать команду для сборки и запуска приложения docker-compose -p app_rag up -d
3. Перейте по ссылке http://localhost:8501/ для входа в приложение
4. Для мониторинга приложения и сбора логов требуется:
    - Перейте по ссылке http://localhost:3000/
    - Подключить datasources loki, по адресу http://loki:3100/
    - В разделе explore/loki - ведем мониторинг приложения и логов.


### Шаги работы с сервисом:

- на первом шаге работы нужно загрузить датасет (обязательно csv файл), параметры датасета указаны на странице, ожидается получить колонку с контекстами, вопросами и ответами.
- производится валидация загружаемого файла (`validate_df.py`), проверяется размер, тип файла, содержимое
- вывод базовой информации о датасете, пропусках и дубликатах (только информирование)
- вывод EDA графиков (`eda.py`):<!-- {"fold":true} -->
  - распределение по длинам текстов в словах (интерактивный график на `plotly`)
  - вывод наиболее часто встречающихся стоп-слов и не стоп-слов
  - вывод Облака слов
  - вывод t-SNE (данный вывод занимает длительное время, требуется выполнить расчет векторов с помощью `TfidfVectorizer`)
- шаг препроцессинга данных и отправка в модель
  - препроцессинг выполняется функцией `prep`, включает в себя удаление стоп-слов, удаление пунктуации и всех символов, не являющихся буквами и цифрами, приведение к нижнему регистру
  - удаление дубликатов и строк с пустыми значениями
- шаг подготовки к обучению:
  - задаются гиперпараментры для векторизации, тип модели -  `tf-idf`  
  - важно указать идентификатор модели (сервис позволяет загрузить несколько моделей)  
  - при нажатии на кнопку “Сохранить параметры” происходит вызов endpoint : `POST/api/v1/models/fit_save`  
- после сохранения модели на бэке данные векторизуются и помещаются в БД `qdrant`, появляются возможности:  
  - загрузить определенную модель для дальнейшего использования (вызов endpoint `POST/api/v1/models/load_model`)  
  - вывести список имеющихся моделей с гиперпараметрами вызов endpoint `POST/api/v1/models/list_model`)  
  - посмотреть список датасетов вызов endpoint `GET/api/v1/models/get_datasets`)  
  - вывести **Бенчмарк**   
  ⚠️ **Важно:** этот пункт заменяет кривые обучения (не актуально для данной модели)  **Бенчмарк** показывает время извлечения ответа из базы данных, тест производится на 100 случайных примеров (используется `POST/api/v1/models/find_context`), взятых из датасета из колонки с вопросами, построен график, на котором можно увидеть распределение времени извлечения текстов по вопросу  
- точность вычисляется на сервере, производится брутфорс для каждого вопроса извлекается ответ и сравнивается с оригинальным по индексам - вызов endpoint `POST/api/v1/models/quality_test`   

- Инференс позволяет ввести тестовой вопрос в поле и получить ответ - вызов endpoint `POST/api/v1/models/find_context`
- Предусмотрена выгрузка моделей,  удаление модели по идентификатору и удаление всех моделей( вызов endpoints: `POST/api/v1/models/unload_model`, `DELETE/api/v1/models/remove/{model_id}`, `DELETE/api/v1/models/remove_all`)  
---------
### Сравнение моделей  

Сервис позволяет обучить и загрузить несколько моделей, и далее **сравнить** модели.  
Инференс можно проводить с помощью любой из загруженных моделей, для этого нужно указать идентификатор модели.  

В секции `Тестирование моделей` можно указать идентификаторы 2-х моделей и вывести бенчмарк и точность для сравнения результатов моделей.  
Если указать идентификатор одной модели, то выводится результат одной модели без сравнения.


## Логирование

Логи хранятся в директории `app/logs/`, разделенные на отдельные файлы для API, основного приложения и операций Qdrant. 

## Инструкция и подробный показ в отдельном видео файле (https://drive.google.com/file/d/1B3RqPt2BVKPCuhqpltTlJFle6sKCiP_t/view?usp=sharing)
