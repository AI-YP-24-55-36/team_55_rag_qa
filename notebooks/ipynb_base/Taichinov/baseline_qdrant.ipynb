{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline —Å qdrant –∏ tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleared_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_train = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_df=0.85, sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_train.fit(train_df[\"context\"])\n",
    "context_test = tfidf_vectorizer_train.transform(test_df['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_all = tfidf_vectorizer_train.transform(df['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 647543 stored elements and shape (2395, 2317171)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(url=\"http://localhost:6333\", timeout=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection(collection_name=\"sparse-coll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_collection(\n",
    "    collection_name='sparse-coll',\n",
    "    vectors_config={},\n",
    "    sparse_vectors_config={\n",
    "        \"text\": models.SparseVectorParams(\n",
    "            index=models.SparseIndexParams(\n",
    "                on_disk=False,\n",
    "            )\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A North London pub Friday night? You‚Äôll lucky get ‚Äòplease‚Äô ‚Äòthank you‚Äô bar staff. The fact Ollie patiently endured pleading smiles ran customer customer pretty amazing. The extra fact finally found spare five minutes indulge sewing knitting blog even amazing. ‚ÄòYes, Karen. My rock god credentials mean I indulge monumental scale give silly witterings iota street cred. No, I won‚Äôt tell best place buy skinny jeans. No, Karen, I won‚Äôt give half pint cider house, matter much beg.‚Äô I‚Äôm wearing Golden Vintage Cardigan took seven weeks knit. You glimpse photo JUST. It‚Äôs pattern Baby Cocktails I‚Äôm big fan knitting designs. That MMJ24 blog post today nothing short miracle. I‚Äôve REALLY busy, getting work clear desk ‚Ä¶ four-day break Paris. But means I missing So Zo‚Äôs Brighton meet-up. I don‚Äôt know whether laugh cry. I imagine everyone Brighton chatting, shopping, comparing notes‚Ä¶ Without me!!!! On hand‚Ä¶ fabric, Paris, fabric, Paris, credit cards, I‚Äôm worth it, fabric, Paris. The fact I booked hotel fact hotel fabric-buying centre Paris utter coincidence people allow book hotels know I serious sewing addiction fault I probably won‚Äôt buy anything anyway really fine I loads fabric don‚Äôt need anything else‚Ä¶ Honest. A bientot! Love photo! Have fabulous time Paris. I‚Äôd love hear favorite fabric spots there. Phwaor! (or sounds effect!) Yum! Have fantabulous time gay Paree! And happen find gorgeous fabric credit card slips sales assistants hands better, I can‚Äôt wait see lovely stuff come home with! I love tough guy sewing-knitting blog. And I intensely jealous four day fabricpalooza Paris. I still kicking buying (geez, I thinking?) left. You *have* get something, rest us live vicariously fabric. Plus, it‚Äôs much easier stranger spend money. üòâ Hmmmm, cute I think‚Ä¶..not sure n stubble all‚Ä¶.ha ha‚Ä¶.what I talking about! I bet arm around like I‚Äôd go girly pathetic- he! FABRIC DISTRICT!!!!!!!!!!!!! PARISSSSSSSSSSSSSSSSSS!!!!!!!!!!!!!!!!!!!! OMG! Have great time. Can‚Äôt wait see find photographed Paris! Px Hahaha, goodluck buying anything part. And great photo! Have fun Paris. ooohhh! fabulous time Paris I can‚Äôt wait see buy!!!!! I‚Äôm missing Brighton meet-up too‚Ä¶sigh‚Ä¶. Wow! Have fun! What French ‚Äúplease I take picture me, sewing blog?‚Äù I‚Äôd like see cardigan! I jut checked Ravelry looks like lovely pattern. Enjoy Paris! Ha‚Ä¶..no fabric buying? Don‚Äôt think so. Lol. You pleased know I buy fabric Brighton‚Ä¶..shocking right? But I think I corrupted bygoldhawk road. I looking forward ur French made pics.\n",
      "What is the author planning to do in Paris?\n"
     ]
    }
   ],
   "source": [
    "print(test_df.iloc[0][\"context\"])\n",
    "print(test_df.iloc[0][\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–ª–µ–¥—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å points=models.Batch - –∑–∞–≥—Ä—É–∑–∫—É –≤ 1 –∑–∞–ø—Ä–æ—Å–µ\n",
    "points = []\n",
    "for i in range(context_test.shape[0]):\n",
    "    indices = context_test[i].indices.tolist()\n",
    "    data = context_test[i].data.tolist()\n",
    "    client.upsert(\n",
    "        collection_name='sparse-coll',\n",
    "        points = [\n",
    "                models.PointStruct(\n",
    "                    id=i,\n",
    "                    payload={\n",
    "                        'source_text': test_df.iloc[i][\"context\"]\n",
    "                    },\n",
    "                    vector={\n",
    "                        'text': models.SparseVector(\n",
    "                            indices=indices, values=data\n",
    "                        )\n",
    "                    },\n",
    "                )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i, row in test_df.iterrows():\n",
    "    query_text = row['question']\n",
    "    query_vec = tfidf_vectorizer_train.transform([query_text])\n",
    "    query_indices = query_vec[0].indices.tolist()\n",
    "    query_data = query_vec[0].data.tolist()\n",
    "    result = client.query_points(\n",
    "        collection_name='sparse-coll',\n",
    "        query=models.SparseVector(\n",
    "            indices=query_indices,\n",
    "            values=query_data,\n",
    "        ),\n",
    "        using=\"text\",\n",
    "        limit=1\n",
    "    )\n",
    "    top_n = len(result.points)\n",
    "    res = [result.points[i].payload['source_text'] for i in range(top_n)]\n",
    "    if row['context'] in res:\n",
    "        correct += 1\n",
    "    \n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8551148225469729\n"
     ]
    }
   ],
   "source": [
    "print(correct/len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded = model.encode(test_df['context'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded = embeded.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection(collection_name=\"hybrid_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_collection(\n",
    "    collection_name='hybrid_collection',\n",
    "    vectors_config={\n",
    "        \"dense_text\": models.VectorParams(\n",
    "            size=len(embeded[0]),\n",
    "            distance=models.Distance.COSINE,\n",
    "        )\n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        \"sparse_text\": models.SparseVectorParams(\n",
    "            index=models.SparseIndexParams(\n",
    "                on_disk=False,\n",
    "            )\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(context_test.shape[0]):\n",
    "    indices = context_test[i].indices.tolist()\n",
    "    data = context_test[i].data.tolist()\n",
    "    embed = embeded[i]\n",
    "    context = test_df.iloc[i][\"context\"]\n",
    "    client.upsert(\n",
    "        collection_name='hybrid_collection',\n",
    "        points = [\n",
    "            models.PointStruct(\n",
    "                id=i,\n",
    "                payload={\n",
    "                    'source_text': context\n",
    "                },\n",
    "                vector={\n",
    "                    'dense_text': embed,\n",
    "                    'sparse_text': models.SparseVector(\n",
    "                        indices=indices, values=data\n",
    "                    ),\n",
    "                },\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i, row in test_df.iterrows():\n",
    "    query_text = row['question']\n",
    "    query_sparse = tfidf_vectorizer_train.transform([query_text])\n",
    "    query_indices = query_vec[0].indices.tolist()\n",
    "    query_data = query_vec[0].data.tolist()\n",
    "    query_dense = model.encode(query_text).tolist()\n",
    "    result = client.query_points(\n",
    "        collection_name=\"hybrid_collection\",\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.SparseVector(indices=query_indices, values=query_data),\n",
    "                using=\"sparse_text\",\n",
    "                limit=20,\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=query_dense,\n",
    "                using=\"dense_text\",\n",
    "                limit=20,\n",
    "            ),\n",
    "        ],\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        limit=1\n",
    "    )\n",
    "    top_n = len(result.points)\n",
    "    res = [result.points[i].payload['source_text'] for i in range(top_n)]\n",
    "    if row['context'] in res:\n",
    "        correct += 1\n",
    "\n",
    "\n",
    "print(correct)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.407098121085595\n"
     ]
    }
   ],
   "source": [
    "print(correct/len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO-DO: Fine-tune sentence-transofrmers \n",
    "[–ò—Å—Ç–æ—á–Ω–∏–∫](https://sbert.net/docs/sentence_transformer/training_overview.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
