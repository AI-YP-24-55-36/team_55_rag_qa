import datetime
import logging
import sys
import time
from pathlib import Path


import matplotlib.pyplot as plt
import numpy as np
import torch
from fastembed import SparseTextEmbedding
from sentence_transformers import CrossEncoder
from qdrant_client import models
from qdrant_client.models import (
    Distance,
    Modifier,
    MultiVectorConfig,
    SparseIndexParams,
    SparseVectorParams,
    VectorParams,
)
from sentence_transformers import SentenceTransformer
from tqdm import tqdm
from transformers import AutoModel, AutoTokenizer

from log_output import Tee
from load_config import load_config

config = load_config()
BASE_DIR = Path(config["paths"]["base_dir"])
LOGS_DIR = BASE_DIR / config["paths"]["logs_dir"]
GRAPHS_DIR = BASE_DIR / config["paths"]["graphs_dir"]
OUTPUT_DIR = BASE_DIR / config["paths"]["output_dir"]
timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
sys.stdout = Tee(f"{OUTPUT_DIR}/log_{timestamp}.txt")

logger = logging.getLogger('hybrid')
logger.setLevel(logging.INFO)
logger.propagate = False

file_handler = logging.FileHandler(f'{LOGS_DIR}/hybrid.log')
file_handler.setLevel(logging.INFO)

# –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–≥–æ–≤
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∫ –ª–æ–≥–≥–µ—Ä—É
logger.addHandler(file_handler)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞
reranker_model = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")

def upload_hybrid_data(client, collection_name: str, data):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Qdrant —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (BM25 + Dense + ColBERT)"""

    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ {len(data)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é {collection_name} —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –ø–æ–∏—Å–∫–æ–º")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è
    collections = client.get_collections().collections
    collection_names = [collection.name for collection in collections]

    if len(collections):
        for el in collection_names:
            client.delete_collection(el)
            print(f"Collection {el} has been cleared")

    # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –∏–Ω–¥–µ–∫—Å–æ–º
    client.create_collection(
        collection_name=collection_name,
        vectors_config={
            "dense": VectorParams(
                size=384,  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å MiniLM
                distance=Distance.COSINE
            ),
            "colbertv2.0": VectorParams(
                size=128,  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å ColBERT
                distance=Distance.COSINE,
                multivector_config=MultiVectorConfig(comparator="max_sim")
            ),
        },
        sparse_vectors_config={
            "bm25": SparseVectorParams(
                index=SparseIndexParams(on_disk=False),
                modifier=Modifier.IDF
            )
        }
    )

    logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —Å–æ–∑–¥–∞–Ω–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")
    print(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —Å–æ–∑–¥–∞–Ω–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    bm25_embedding_model = SparseTextEmbedding("Qdrant/bm25")
    dense_embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
    colbert_embedding_model = AutoModel.from_pretrained("colbert-ir/colbertv2.0")
    colbert_tokenizer = AutoTokenizer.from_pretrained("colbert-ir/colbertv2.0")

    # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏ –∏ –Ω–∞ CPU
    colbert_embedding_model.eval()
    colbert_embedding_model = colbert_embedding_model.to('cpu')

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
    points = []

    try:
        for item in tqdm(data):
            text = item["context"]

            try:
                # BM25 –≤–µ–∫—Ç–æ—Ä
                sparse_vector = list(bm25_embedding_model.query_embed(text))
                sparse_embedding = sparse_vector[0] if sparse_vector else None

                # Dense –≤–µ–∫—Ç–æ—Ä (MiniLM)
                dense_embedding = dense_embedding_model.encode(text)
                dense_embedding = dense_embedding.tolist()

                # ColBERT –≤–µ–∫—Ç–æ—Ä
                inputs = colbert_tokenizer(
                    text,
                    return_tensors="pt",
                    padding=True,
                    truncation=True,
                    max_length=512  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                )

                with torch.no_grad():
                    outputs = colbert_embedding_model(**inputs)
                    # –ë–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–µ–µ –ø–æ —Ç–æ–∫–µ–Ω–∞–º –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω—É–∂–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
                    colbert_embedding = outputs.last_hidden_state.mean(dim=1).squeeze(0)
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è
                    if len(colbert_embedding.shape) > 1:
                        colbert_embedding = colbert_embedding.mean(dim=0)
                    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω—É–∂–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    if colbert_embedding.shape[0] != 128:
                        colbert_embedding = torch.nn.functional.interpolate(
                            colbert_embedding.unsqueeze(0).unsqueeze(0),
                            size=128,
                            mode='linear'
                        ).squeeze()

                    colbert_embedding = colbert_embedding.cpu().numpy().tolist()

                # –°–æ–∑–¥–∞–µ–º —Ç–æ—á–∫—É –¥–∞–Ω–Ω—ã—Ö
                point = models.PointStruct(
                    id=item["id"],
                    payload=item,
                    vector={
                        "bm25": {
                            "values": sparse_embedding.values.tolist() if sparse_embedding else [],
                            "indices": sparse_embedding.indices.tolist() if sparse_embedding else []
                        },
                        "dense": dense_embedding,
                        "colbertv2.0": colbert_embedding
                    }
                )
                points.append(point)

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {item['id']}: {str(e)}")
                continue

        print(f"–°–æ–∑–¥–∞–Ω–æ {len(points)} points")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ Qdrant –±–∞—Ç—á–∞–º–∏
        batch_size = 100
        for i in range(0, len(points), batch_size):
            batch = points[i:i + batch_size]
            client.upload_points(
                collection_name=collection_name,
                points=batch
            )
            print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {i + len(batch)} –∏–∑ {len(points)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

        logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é {collection_name}")
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é {collection_name}")

    except Exception as e:
        logger.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        raise


def benchmark_hybrid_rerank(client, collection_name, test_data, top_k_values=[1, 3], reranker=None):
    print(f"\nüîç –ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ì–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ü–æ–∏—Å–∫–∞ + –†–µ—Ä–∞–Ω–∫–∞ –¥–ª—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection_name}'")
    logger.info(f"–ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ì–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ü–æ–∏—Å–∫–∞ + –†–µ—Ä–∞–Ω–∫–∞ –¥–ª—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection_name}'")

    results = {
        "speed": {
            "avg_time": 0,
            "median_time": 0,
            "max_time": 0,
            "min_time": 0,
            "query_times": []
        },
        "accuracy": {
            "before_rerank": {k: {"correct": 0, "total": 0, "accuracy": 0} for k in top_k_values},
            "after_rerank": {k: {"correct": 0, "total": 0, "accuracy": 0} for k in top_k_values}
        }
    }

    max_top_k = max(top_k_values)
    total_queries = len(test_data)

    logger.info(f"–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ Hybrid Search –¥–ª—è {total_queries} –∑–∞–ø—Ä–æ—Å–æ–≤")
    print(f"‚è±Ô∏è  –ò–∑–º–µ—Ä–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞...")

    progress_bar = tqdm(total=total_queries, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤", unit="–∑–∞–ø—Ä–æ—Å")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    bm25_embedding_model = SparseTextEmbedding("Qdrant/bm25")
    dense_embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
    colbert_embedding_model = AutoModel.from_pretrained("colbert-ir/colbertv2.0")
    colbert_tokenizer = AutoTokenizer.from_pretrained("colbert-ir/colbertv2.0")

    # –ü–µ—Ä–µ–≤–æ–¥–∏–º ColBERT –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏ –∏ –Ω–∞ CPU
    colbert_embedding_model.eval()
    colbert_embedding_model = colbert_embedding_model.to('cpu')

    for idx, row in test_data.iterrows():
        query_text = row['question']
        true_context = row['context']


        # BM25 –≤–µ–∫—Ç–æ—Ä
        sparse_vector = list(bm25_embedding_model.query_embed(query_text))
        sparse_embedding = sparse_vector[0] if sparse_vector else None

        # Dense –≤–µ–∫—Ç–æ—Ä (MiniLM)
        dense_embedding = dense_embedding_model.encode(query_text)
        dense_embedding = dense_embedding.tolist()

        # ColBERT –≤–µ–∫—Ç–æ—Ä
        inputs = colbert_tokenizer(
            query_text,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=512
        )

        with torch.no_grad():
            outputs = colbert_embedding_model(**inputs)
            colbert_embedding = outputs.last_hidden_state.mean(dim=1).squeeze(0)
            if len(colbert_embedding.shape) > 1:
                colbert_embedding = colbert_embedding.mean(dim=0)
            if colbert_embedding.shape[0] != 128:
                colbert_embedding = torch.nn.functional.interpolate(
                    colbert_embedding.unsqueeze(0).unsqueeze(0),
                    size=128,
                    mode='linear'
                ).squeeze()
            colbert_embedding = colbert_embedding.cpu().numpy().tolist()

        # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞
        start_time = time.time()

        # –°–æ–∑–¥–∞–µ–º prefetch –∑–∞–ø—Ä–æ—Å—ã
        prefetch = [
            models.Prefetch(
                query=dense_embedding,
                using="dense",
                limit=20,
            ),
            models.Prefetch(
                query=models.SparseVector(
                    indices=sparse_embedding.indices.tolist() if sparse_embedding else [],
                    values=sparse_embedding.values.tolist() if sparse_embedding else []
                ),
                using="bm25",
                limit=20,
            ),
        ]

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        search_results = client.query_points(
            collection_name,
            prefetch=prefetch,
            query=colbert_embedding,
            using="colbertv2.0",
            with_payload=True,
            limit=max_top_k,
        )

        end_time = time.time()
        query_time = end_time - start_time
        results["speed"]["query_times"].append(query_time)


        found_contexts = []
        for point in search_results.points:
            context = point.payload.get('context', '')
            score = point.score  # –û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
            found_contexts.append((context, score))


        for k in top_k_values:
            results["accuracy"]["before_rerank"][k]["total"] += 1
            if true_context in found_contexts[0][:k]:
                results["accuracy"]["before_rerank"][k]["correct"] += 1

        # –†–µ—Ä–µ–π–∫–∏–Ω–≥ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
        if reranker:
            found_contexts_r = reranker(query_text, found_contexts)

    # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ —Ä–µ—Ä–µ–π–∫–∏–Ω–≥–∞
            for k in top_k_values:
                results["accuracy"]["after_rerank"][k]["total"] += 1
                if true_context in found_contexts_r[:k]:
                    results["accuracy"]["after_rerank"][k]["correct"] += 1

        progress_bar.update(1)

    progress_bar.close()

    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∫–æ—Ä–æ—Å—Ç–∏
    query_times = results["speed"]["query_times"]
    if query_times:
        results["speed"]["avg_time"] = sum(query_times) / len(query_times)
        results["speed"]["median_time"] = sorted(query_times)[len(query_times) // 2]
        results["speed"]["max_time"] = max(query_times)
        results["speed"]["min_time"] = min(query_times)
    del results["speed"]["query_times"]

    # –í—ã—á–∏—Å–ª—è–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å
    for stage in ["before_rerank", "after_rerank"]:
        for k in top_k_values:
            correct = results["accuracy"][stage][k]["correct"]
            total = results["accuracy"][stage][k]["total"]
            accuracy = correct / total if total > 0 else 0
            results["accuracy"][stage][k]["accuracy"] = accuracy
            logger.info(f"Hybrid Search {stage.replace('_', ' ')} (top-{k}): {accuracy:.4f} ({correct}/{total})")

    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∫–æ—Ä–æ—Å—Ç–∏
    logger.info(f"Hybrid Search –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {results['speed']['avg_time'] * 1000:.2f} –º—Å")
    logger.info(f"Hybrid Search –ú–µ–¥–∏–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {results['speed']['median_time'] * 1000:.2f} –º—Å")
    logger.info(f"Hybrid Search –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {results['speed']['max_time'] * 1000:.2f} –º—Å")
    logger.info(f"Hybrid Search –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {results['speed']['min_time'] * 1000:.2f} –º—Å")

    print(f"‚úÖ –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ Hybrid Search –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection_name}'")

    return results

def reranker(query, candidates):

    texts = [(query, context) for context, _ in candidates]
    scores = reranker_model.predict(texts)

    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –æ—Ü–µ–Ω–∫–∏ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–∏–º
    reranked_results = sorted(zip(candidates, scores), key=lambda x: x[1], reverse=True)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –≤ –Ω–æ–≤–æ–º –ø–æ—Ä—è–¥–∫–µ
    return [context for (context, _), _ in reranked_results]


def print_comparison(results_without_rerank, results_with_rerank, top_k_values=[1, 3]):
    print("\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Hybrid Search —Å —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º –∏ –±–µ–∑ –Ω–µ–≥–æ:\n")

    print("‚è≥ –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞:")
    print(f"  - –ë–µ–∑ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞: {results_without_rerank['speed']['avg_time'] * 1000:.2f} –º—Å")
    print(f"  - –° —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º: {results_with_rerank['speed']['avg_time'] * 1000:.2f} –º—Å")

    print("\nüéØ –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞ (Accuracy):")
    for k in top_k_values:
        acc_before = results_without_rerank["accuracy"]["before_rerank"][k]["accuracy"]
        acc_after = results_with_rerank["accuracy"]["after_rerank"][k]["accuracy"]

        print(f"  - Top-{k}:")
        print(f"    - –ë–µ–∑ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞: {acc_before:.4f}")
        print(f"    - –° —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º: {acc_after:.4f}")


def visualize_results_rerank(results_without_rerank, results_with_rerank, top_k_values=[1, 3],
                             title_prefix="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º –∏ –±–µ–∑", save_dir=f"{GRAPHS_DIR}"):

    print(f"\nüìä –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞...")
    logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞")

    print(save_dir)

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    Path(save_dir).mkdir(exist_ok=True, parents=True)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
    timestr = time.strftime("%Y%m%d_%H%M%S")  # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Å–∏–º–≤–æ–ª—ã –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –¥–æ–ø—É—Å—Ç–∏–º—ã

    # --- 1Ô∏è‚É£ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è ---
    plt.figure(figsize=(10, 5))

    speeds = [
        results_without_rerank['speed']['avg_time'] * 1000,  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
        results_with_rerank['speed']['avg_time'] * 1000
    ]

    bar_width = 0.8 /2
    n_groups = len(top_k_values)
    index = np.arange(n_groups)
    colors = plt.cm.tab10(np.linspace(0, 1, 2))
    labels = ["–ë–µ–∑ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞", "–° —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º"]  # –ü–æ–¥–ø–∏—Å–∏ —Å—Ç–æ–ª–±—Ü–æ–≤

    # # –°–æ–∑–¥–∞—ë–º –≥—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–∏

    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å—Ç–æ–ª–±—á–∞—Ç–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã
    plt.bar(
        index,
        speeds,
        bar_width,
        color=colors,  # –¶–≤–µ—Ç–∞ —Å—Ç–æ–ª–±—Ü–æ–≤
        edgecolor='black',  # –¶–≤–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã —Å—Ç–æ–ª–±—Ü–æ–≤
        linewidth=0.5,  # –¢–æ–ª—â–∏–Ω–∞ –≥—Ä–∞–Ω–∏—Ü—ã —Å—Ç–æ–ª–±—Ü–æ–≤
    )

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞–¥ —Å—Ç–æ–ª–±—Ü–∞–º–∏
    for i, v in enumerate(speeds):
        if v > 0:
            plt.text(
                index[i],
                v + 1,
                f"{v:.1f}",
                ha='center',
                va='bottom',
                fontsize=6,
            )
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Å–µ–π
    plt.xticks(index, labels)
    plt.ylabel("–í—Ä–µ–º—è (–º—Å)")
    plt.title(f"{title_prefix}: –í—Ä–µ–º—è –ø–æ–∏—Å–∫–∞")

    # –°–µ—Ç–∫–∞ –¥–ª—è –æ—Å–∏ Y
    plt.grid(axis='y', linestyle='--', alpha=0.7)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ (–¥–æ plt.show())
    speed_save_path = f"{save_dir}/speed_comparison_{timestr}_hybrid.png"
    plt.savefig(speed_save_path, dpi=300, bbox_inches='tight')

    # --- 2Ô∏è‚É£ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞ ---
    plt.figure(figsize=(10, 5))
    acc_before = [results_without_rerank["accuracy"]["before_rerank"][k]["accuracy"] for k in top_k_values]
    acc_after = [results_with_rerank["accuracy"]["after_rerank"][k]["accuracy"] for k in top_k_values]

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
    bar_width = 0.8 / 2
    n_groups = len(top_k_values)
    index = np.arange(n_groups)
    colors = plt.cm.tab10(np.linspace(0, 1, 2))
    labels = ["–ë–µ–∑ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞", "–° —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º"]

    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å—Ç–æ–ª–±—á–∞—Ç–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
    plt.bar(
        index - bar_width / 2,
        acc_before,
        bar_width,
        label=labels[0],
        color=colors[0],
        edgecolor='black',
        linewidth=0.5,
    )

    plt.bar(
        index + bar_width / 2,
        acc_after,
        bar_width,
        label=labels[1],
        color=colors[1],
        edgecolor='black',
        linewidth=0.5,
    )

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞–¥ —Å—Ç–æ–ª–±—Ü–∞–º–∏
    for i, (v_before, v_after) in enumerate(zip(acc_before, acc_after)):
        if v_before > 0:
            plt.text(
                index[i] - bar_width / 2,
                v_before + 0.01,
                f"{v_before:.2f}",
                ha='center',
                va='bottom',
                fontsize=6,
            )
        if v_after > 0:
            plt.text(
                index[i] + bar_width / 2,
                v_after + 0.01,
                f"{v_after:.2f}",
                ha='center',
                va='bottom',
                fontsize=6,
            )

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Å–µ–π
    plt.xticks(index, [f"Top-{k}" for k in top_k_values])
    plt.ylabel("–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)")
    plt.title(f"{title_prefix}: –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞")

    # –õ–µ–≥–µ–Ω–¥–∞ –∏ —Å–µ—Ç–∫–∞
    plt.legend()
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    accuracy_save_path = f"{save_dir}/accuracy_comparison_{timestr}_hybrid.png"
    plt.savefig(accuracy_save_path, dpi=300, bbox_inches='tight')