import argparse
import os
import time
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.http.models import Distance, SearchParams, HnswConfigDiff
from read_data_from_csv import read_data
from cache_embed import generate_and_save_embeddings
from logger_init import setup_paths, setup_logging
from visualisation import visualize_results
from bench import benchmark_performance
from hybrid_rerank import print_comparison, run_bench_hybrid
from visualisation import visualize_results_rerank
from sparse_bm25 import upload_bm25_data, benchmark_bm25
from report_data import print_speed_results, print_accuracy_results


BASE_DIR, LOGS_DIR, GRAPHS_DIR, OUTPUT_DIR = setup_paths()
logger = setup_logging(LOGS_DIR, OUTPUT_DIR)
os.environ["TOKENIZERS_PARALLELISM"] = "false"


def parse_args():
    parser = argparse.ArgumentParser(description='–ë–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã')
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Qdrant
    parser.add_argument('--qdrant-host', type=str, default='localhost',
                        help='–•–æ—Å—Ç Qdrant —Å–µ—Ä–≤–µ—Ä–∞')
    parser.add_argument('--qdrant-port', type=int, default=6333,
                        help='–ü–æ—Ä—Ç Qdrant —Å–µ—Ä–≤–µ—Ä–∞')
    parser.add_argument('--collection-name', type=str, default='rag',
                        help='–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ Qdrant')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –∏ –ø–æ–∏—Å–∫–∞
    parser.add_argument('--model-names', nargs='+',
                        default=[
                            'all-MiniLM-L6-v2', 'paraphrase-multilingual-MiniLM-L12-v2', 'BM25'],
                        help='–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—è BM25')
    parser.add_argument('--vector-size', type=int, default=384,
                        help='–†–∞–∑–º–µ—Ä –≤–µ–∫—Ç–æ—Ä–æ–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤')
    parser.add_argument('--batch-size', type=int, default=100,
                        help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--limit', type=int, default=100,
                        help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è')

    # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã HNSW –¥–ª—è dense –º–æ–¥–µ–ª–µ–π
    parser.add_argument('--hnsw-ef', type=int, default=16,
                        help='–ü–∞—Ä–∞–º–µ—Ç—Ä ef –¥–ª—è HNSW')
    parser.add_argument('--hnsw-m', type=int, default=16,
                        help='–ü–∞—Ä–∞–º–µ—Ç—Ä m –¥–ª—è HNSW (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π)')
    parser.add_argument('--ef-construct', type=int, default=200,
                        help='–ü–∞—Ä–∞–º–µ—Ç—Ä ef_construct –¥–ª—è HNSW')

    parser.add_argument('--hybrid', type=int, default=0,
                        help='–ü–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞')

    return parser.parse_args()


def create_collection(client, collection_name, vector_size, distance=Distance.COSINE):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ Qdrant"""
    collections = client.get_collections().collections
    collection_names = [collection.name for collection in collections]

    if collection_name in collection_names:
        client.delete_collection(collection_name)
        logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —É–¥–∞–ª–µ–Ω–∞")

    # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é —Å –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏
    client.create_collection(
        collection_name=collection_name,
        vectors_config={
            "context": {
                "size": vector_size,
                "distance": distance
            }
        }
    )
    logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —Å–æ–∑–¥–∞–Ω–∞")

def upload_data(client, collection_name, data, model, batch_size=100):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Qdrant"""
    logger.info(
        f"–ó–∞–≥—Ä—É–∑–∫–∞ {len(data)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é {collection_name}")
    start_time = time.time()
    progress_bar = tqdm(
        total=len(data), desc="–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö", unit="–¥–æ–∫—É–º–µ–Ω—Ç")
    # –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–∞–º–∏
    for i in range(0, len(data), batch_size):
        batch = data[i:i + batch_size]
        texts = [item["context"] for item in batch]

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –±–∞—Ç—á–∞
        args = parse_args()
        vectors = generate_and_save_embeddings(
            texts=texts,
            model=model,
            array_name=f'{collection_name}+{args.limit}',
            save_dir="embeddings"
        )

        points = []
        for j, (item, vector) in enumerate(zip(batch, vectors)):
            points.append({
                "id": item["id"],
                "vector": {
                    "context": vector.tolist()
                },
                "payload": item
            })

        client.upsert(
            collection_name=collection_name,
            points=points
        )

        progress_bar.update(len(batch))
        if (i + batch_size) % 1000 == 0 or (i + batch_size) >= len(data):
            logger.info(
                f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {min(i + batch_size, len(data))}/{len(data)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
    progress_bar.close()
    elapsed_time = time.time() - start_time
    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
    print(f"‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")


def benchmark_dense_models(client, models_to_compare, model_instances, search_algorithms, args, data_for_db, data_df):
    speed_results = {}
    accuracy_results = {}

    for model_name in models_to_compare:
        model = model_instances[model_name]
        collection_name = f"{args.collection_name}_{model_name.replace('-', '_')}"
        create_collection(client, collection_name, args.vector_size)
        upload_data(client, collection_name, data_for_db, model, args.batch_size)

        speed_results[model_name] = {}
        accuracy_results[model_name] = {}

        for algo_name, search_params in search_algorithms.items():
            logger.info(f"–û—Ü–µ–Ω–∫–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ {algo_name} —Å –º–æ–¥–µ–ª—å—é {model_name}")
            print(f"\nüîç –û—Ü–µ–Ω–∫–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ {algo_name} —Å –º–æ–¥–µ–ª—å—é {model_name}")

            if algo_name.startswith("HNSW"):
                client.update_collection(
                    collection_name=collection_name,
                    hnsw_config=HnswConfigDiff(
                        m=args.hnsw_m,
                        ef_construct=args.ef_construct,
                    )
                )

            benchmark_results = benchmark_performance(
                client=client,
                collection_name=collection_name,
                test_data=data_df,
                model=model,
                search_params=search_params,
                top_k_values=[1, 3]
            )

            speed_results[model_name][algo_name] = benchmark_results["speed"]
            accuracy_results[model_name][algo_name] = benchmark_results["accuracy"]

    return speed_results, accuracy_results

def benchmark_bm25_model(client, base_collection_name, data_for_db, data_df, search_algorithms, args):
    print("\n" + "=" * 80)
    print("üîç –û–¶–ï–ù–ö–ê –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò BM25")
    print("=" * 80)

    logger.info("–ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ BM25")

    bm25_collection_name = f"{base_collection_name}_bm25"
    upload_bm25_data(client, bm25_collection_name, data_for_db)

    bm25_speed_results = {}
    bm25_accuracy_results = {}

    for algo_name, search_params in search_algorithms.items():
        logger.info(f"–û—Ü–µ–Ω–∫–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ {algo_name} —Å –º–æ–¥–µ–ª—å—é BM25")
        print(f"\nüîç –û—Ü–µ–Ω–∫–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ {algo_name} —Å –º–æ–¥–µ–ª—å—é BM25")

        benchmark_results = benchmark_bm25(
            client=client,
            collection_name=bm25_collection_name,
            test_data=data_df,
            search_params=search_params,
            top_k_values=[1, 3]
        )

        bm25_speed_results[algo_name] = benchmark_results["speed"]
        bm25_accuracy_results[algo_name] = benchmark_results["accuracy"]

    return {
        "speed": bm25_speed_results,
        "accuracy": bm25_accuracy_results
    }


def initialize_models(all_models, args, client, data_for_db):
    models_to_compare = [m for m in all_models if m != 'BM25']
    use_bm25 = 'BM25' in all_models
    model_instances = {}

    if models_to_compare:
        print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –¥–ª—è dense –≤–µ–∫—Ç–æ—Ä–æ–≤...")
        progress_bar = tqdm(total=len(models_to_compare), desc="–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π", unit="–º–æ–¥–µ–ª—å")

        for model_name in models_to_compare.copy():
            try:
                logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏: {model_name}")
                model_instances[model_name] = SentenceTransformer(model_name)
                progress_bar.update(1)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
                models_to_compare.remove(model_name)
        progress_bar.close()
        print(f"‚úÖ –ú–æ–¥–µ–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã: {', '.join(models_to_compare)}")

    search_algorithms = {
        "Exact Search": SearchParams(exact=True),
        f"HNSW Users ef={args.hnsw_ef}": SearchParams(hnsw_ef=args.hnsw_ef),
        "HNSW High Precision ef=512": SearchParams(hnsw_ef=512)
    }

    bm25_model = None
    if use_bm25:
        print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ BM25...")
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ BM25")
        bm25_model = 'BM25'

        bm25_collection_name = f"{args.collection_name}_bm25"
        upload_bm25_data(client, bm25_collection_name, data_for_db)

        search_algorithms = {"Exact Search": SearchParams(exact=True)}

    return models_to_compare, bm25_model, model_instances, search_algorithms

def run_full_benchmark(client, all_models, args, data_for_db, data_df):
    models_to_compare, bm25_model, model_instances, search_algorithms = initialize_models(all_models, args,
                                                                                          client, data_for_db)

    speed_results = {}
    accuracy_results = {}

    # –ë–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è dense –º–æ–¥–µ–ª–µ–π
    if models_to_compare:
        speed_results, accuracy_results = benchmark_dense_models(
            client, models_to_compare, model_instances, search_algorithms, args, data_for_db, data_df
        )

    # –ë–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è BM25
    bm25_results = None
    if bm25_model:
        bm25_results = benchmark_bm25_model(
            client, args.collection_name, data_for_db, data_df, search_algorithms, args
        )

    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print_speed_results(speed_results, bm25_results, models_to_compare)
    print_accuracy_results(accuracy_results, bm25_results, models_to_compare)

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    if models_to_compare or bm25_model:
        visualize_results(
            speed_results=speed_results,
            accuracy_results=accuracy_results,
            bm25_results=bm25_results,
            title_prefix="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ RAG —Å–∏—Å—Ç–µ–º—ã",
            save_dir="./logs/graphs"
        )

    logger.info("–ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
    print("\n" + "=" * 80)
    print("‚úÖ –ë–ï–ù–ß–ú–ê–†–ö –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û")
    print("–ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ ./logs/graphs/")
    print("=" * 80)


def main():
    args = parse_args()
    hybrid = args.hybrid
    print("\n" + "="*80)
    print("üöÄ –ó–ê–ü–£–°–ö –ë–ï–ù–ß–ú–ê–†–ö–ê RAG –°–ò–°–¢–ï–ú–´")
    print("="*80)
    logger.info("–ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞ RAG —Å–∏—Å—Ç–µ–º—ã")

    # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Qdrant
    client = QdrantClient(host=args.qdrant_host, port=args.qdrant_port)
    # –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å limit={args.limit}")
    print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (limit={args.limit})...")

    data_for_db, data_df = read_data(limit=args.limit)
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data_for_db)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data_for_db)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    if hybrid == 0:

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        all_models = args.model_names
        logger.info(f"–í—ã–±—Ä–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {', '.join(all_models)}")
        print(f"üîÑ –í—ã–±—Ä–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {', '.join(all_models)}")

        run_full_benchmark(client, all_models, args, data_for_db, data_df)

    # –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –≤ –≥–∏–±—Ä–∏–¥–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
    elif hybrid == 1:
        print("\n" + "=" * 80)
        print("üöÄ –ó–ê–ü–£–°–ö –ë–ï–ù–ß–ú–ê–†–ö–ê RAG –°–ò–°–¢–ï–ú–´ –° –ì–ò–ë–†–ò–î–ù–´–ú –ü–û–ò–°–ö–û–ú")
        print("=" * 80)
        logger.info("–ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞ RAG —Å–∏—Å—Ç–µ–º—ã")

        args = parse_args()
        data_for_db, data_df = read_data(limit=args.limit)
        client = QdrantClient(host=args.qdrant_host, port=args.qdrant_port)
        results_without_rerank, results_with_rerank = run_bench_hybrid(client, data_for_db, data_df)
        print_comparison(results_without_rerank, results_with_rerank)
        visualize_results_rerank(results_without_rerank, results_with_rerank)
        logger.info("–ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        print("\n" + "=" * 80)
        print("‚úÖ –ë–ï–ù–ß–ú–ê–†–ö –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û")
        print(f"–ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {GRAPHS_DIR}")
        print("=" * 80)


if __name__ == "__main__":
    main()