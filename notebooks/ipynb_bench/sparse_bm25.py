import time
from tqdm import tqdm
from fastembed import SparseTextEmbedding
from qdrant_client import models
from logger_init import setup_paths, setup_logging
from report_data import (init_results, evaluate_accuracy,
                         calculate_speed_stats, compute_final_accuracy,
                         log_topk_accuracy, log_speed_stats)


BASE_DIR, LOGS_DIR, GRAPHS_DIR, OUTPUT_DIR = setup_paths()
logger = setup_logging(LOGS_DIR, OUTPUT_DIR)

def create_coll(client, collection_name):
    collections = client.get_collections().collections
    collection_names = [collection.name for collection in collections]

    if collection_name in collection_names:
        client.delete_collection(collection_name)
        logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —É–¥–∞–ª–µ–Ω–∞")

    # —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏—é —Å BM25-–∏–Ω–¥–µ–∫—Å–æ–º
    client.create_collection(
        collection_name=collection_name,
        vectors_config={},
        sparse_vectors_config={
            "bm25": models.SparseVectorParams(
                index=models.SparseIndexParams(on_disk=False),
                modifier=models.Modifier.IDF
            )
        },
        hnsw_config=models.HnswConfigDiff(
            m=0, )  # –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞
    ),

    logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —Å–æ–∑–¥–∞–Ω–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π BM25")



def upload_bm25_data(client, collection_name, data):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Qdrant —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ BM25"""

    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ {len(data)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é {collection_name} —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º BM25")
    # –ø—Ä–æ–≤–µ—Ä–∫–∞, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è
    create_coll(client, collection_name)
    # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    bm25_embedding_model = SparseTextEmbedding("Qdrant/bm25")

    points = []
    # —Å–æ–∑–¥–∞–Ω–∏–µ –ø–æ–∏–Ω—Ç–æ–≤
    for item in data:
        vector = list(bm25_embedding_model.query_embed(item["context"]))
        if vector:
            sparse_embedding = vector[0]
            points.append(
                models.PointStruct(
                    id=item["id"],
                    payload=item,
                    vector={
                        "bm25": {
                            "values": sparse_embedding.values.tolist(),
                            "indices": sparse_embedding.indices.tolist()
                        }
                    }
                )
            )

    # –∑–∞–≥—Ä—É–∑–∫–∞ –ø–æ–∏–Ω—Ç–æ–≤
    client.upload_points(
        collection_name=collection_name,
        points=points
    )

    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {collection_name}")


def prepare_sparse_vector(model, text):
    vector = list(model.query_embed(text))[0]
    return {
        "indices": vector.indices.tolist(),
        "values": vector.values.tolist()
    }

def search_bm25(client, collection_name, sparse_vector, limit, search_params):
    start_time = time.time()
    results = client.query_points(
        collection_name=collection_name,
        query=models.SparseVector(
            indices=sparse_vector["indices"],
            values=sparse_vector["values"]
        ),
        using="bm25",
        limit=limit,
        search_params=search_params
    )
    end_time = time.time()
    return results, end_time - start_time

def benchmark_bm25(client, collection_name, test_data, search_params=None, top_k_values=[1, 3]):
    print(f"\nüîç –ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ BM25 –¥–ª—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection_name}'")
    logger.info(f"–ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ BM25 –¥–ª—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection_name}'")

    results = init_results(top_k_values)
    max_top_k = max(top_k_values)
    total_queries = len(test_data)

    logger.info(f"–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ BM25 –¥–ª—è {total_queries} –∑–∞–ø—Ä–æ—Å–æ–≤")
    print(f"‚è±Ô∏è  –ò–∑–º–µ—Ä–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞ BM25...")

    progress_bar = tqdm(total=total_queries, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ BM25", unit="–∑–∞–ø—Ä–æ—Å")
    bm25_embedding_model = SparseTextEmbedding("Qdrant/bm25")

    for idx, row in test_data.iterrows():
        query_text = row['question']
        true_context = row['context']

        sparse_vector = prepare_sparse_vector(bm25_embedding_model, query_text)
        search_results, query_time = search_bm25(client, collection_name, sparse_vector, max_top_k, search_params)
        results["speed"]["query_times"].append(query_time)

        found_contexts = [point.payload.get('context', '') for point in search_results.points]

        evaluate_accuracy(results["accuracy"], found_contexts, true_context, top_k_values, query_text, idx)
        progress_bar.update(1)

    progress_bar.close()
    calculate_speed_stats(results)
    compute_final_accuracy(results)
    log_topk_accuracy(results, top_k_values)
    log_speed_stats(results)


    print(f"‚úÖ –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ BM25 –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection_name}'")
    return results