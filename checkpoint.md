# Построение вопросно-ответной системы с использованием RAG (retrieval-augmented generation)

## План выполнения проекта:

## 1 этап (retrieval)

### Задача: изучить данные, выбрать БД, выбрать тип эмбеддингов

1. Изучение датасета https://huggingface.co/datasets/neural-bridge/rag-dataset-12000 (проверка на адекватность, посмотреть соответствие количества контекстов и ответов)

  - EDA: Анализ на пропуски, сравнение длин текстов, выявление аномалий, выбросов. Построение графиков. 
  - Очистка данных, проверка корректности данных
2. Построение эмбеддингов:
  - Создание БД (Qdrant) эмбеддингов из датасета 
  - выбор размера chunk, кодирование контекста и вопросов
  - Сравнение разных вариантов эмбеддингов
  - dense / sparse / hybrid / multivector, +  reranking (cross encoders)
  - Подбор параметров извлечения из бд Qdrant
  - Выбрать метрики:
  - (mrr, hit rate, recall @ k, precision @ k)	
3. Определиться с подходом и выбрать параметры для построения модели эмбеддингов

4. Оценить результаты
  - зафиксировать результат и сохранить БД
5. Посмотреть более сложные подходы к построению эмбеддингов, сравнить результаты


## 2 этап (generation)

1. Работа над генерацией ответов:
  - подбор модели для генерации ответа (Llama/Mistral/GigaChat/etc)
  - подбор архитектуры модели
  - выбор метрик для оценки работы модели
  - оценка результатов работы модели 
  - результирующее обучение, сохранение/фиксация модели

2. Промтинг, метрики/оценка, ускорение работы
  - Применение техник преобразования запросов (перефразирование/подзапросы и т.д.)
3. Улучшение генерации
4. Оптимизация параметров извлечения информации (кол-во релевантных контекстов)

## 3 этап (обертка)

### Задача: обернуть созданную модель в интерфейсный сервис в виде приложения
1. Выбор платформы telegram bot/streamlit 
2. Разработки интерфейса приложения
3. Тестирование
4. Развертывание  приложения на облачном сервере


### Используемый стэк для разработки:
- sentence_transformers 
- hf datasets 
- hf transformers
- PromptTemplate
